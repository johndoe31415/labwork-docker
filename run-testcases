#!/usr/bin/python3
#	labwork-docker - Docker-based system for evaluation labwork
#	Copyright (C) 2021-2022 Johannes Bauer
#
#	This file is part of labwork-docker.
#
#	labwork-docker is free software; you can redistribute it and/or modify
#	it under the terms of the GNU General Public License as published by
#	the Free Software Foundation; this program is ONLY licensed under
#	version 3 of the License, later versions are explicitly excluded.
#
#	labwork-docker is distributed in the hope that it will be useful,
#	but WITHOUT ANY WARRANTY; without even the implied warranty of
#	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#	GNU General Public License for more details.
#
#	You should have received a copy of the GNU General Public License
#	along with labwork-docker; if not, write to the Free Software
#	Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
#	Johannes Bauer <JohannesBauer@gmx.de>

import os
import sys
import time
import json
import subprocess
import collections
from FriendlyArgumentParser import FriendlyArgumentParser

parser = FriendlyArgumentParser(description = "Executor of labwork submission file.")
parser.add_argument("-n", "--no-network-isolation", action = "store_true", help = "By default, the images that are executed inside the container are fully network-isolated (in a 'nonat' network with no DNS). This option disables this security feature. It is only intended for use with trusted submission files (i.e., for testing or for trying your own submissions)")
parser.add_argument("-u", "--server-uri", metavar = "uri", default = "http://172.18.0.1:5000/", help = "URI of the test server endpoint. Defaults to %(default)s.")
parser.add_argument("-v", "--verbose", action = "count", default = 0, help = "Increases verbosity. Can be specified multiple times to increase.")
parser.add_argument("-c", "--client-id", metavar = "client_id", required = True, help = "Client ID to use for the labwork client. Mandatory argument.")
parser.add_argument("-a", "--assignment", metavar = "assignment_name", required = True, help = "Assignment name to execute. Mandatory argument.")
parser.add_argument("-e", "--docker-executable", metavar = "executable", default = "docker", help = "Specify an executable to run the containers. Useful if e.g. podman should be used instead of docker.")
parser.add_argument("-i", "--docker-image", metavar = "docker_image", default = "ghcr.io/johndoe31415/labwork-docker:master", help = "Specify a custom container image, e.g. a locally built one.")
parser.add_argument("-t", "--timeout-secs", metavar = "secs", type = float, default = 30.0, help = "Terminate clients after this amoung of time, in seconds. Defaults to %(default).1f seconds.")
parser.add_argument("submission_file", metavar = "filename", help = "Submission .tar.gz archive")
args = parser.parse_args(sys.argv[1:])

class TestcaseRunner():
	_Instance = collections.namedtuple("Instance", [ "src_file", "container_id", "start_time" ])
	_FinishedInstance = collections.namedtuple("FinishedInstance", [ "instance", "exit", "returncode", "log" ])

	def __init__(self, args):
		self._args = args
		self._running_instances = [ ]
		self._finished_instances = [ ]
		self._timed_out_instances = [ ]
		self._collected_results = [ ]

	def run(self, submission_file):
		if not os.path.isfile(submission_file):
			print("Ignoring non-file or nonexistent: %s" % (submission_file))
			return
		if not submission_file.endswith(".tar.gz"):
			print("Ignoring non-.tar.gz: %s" % (submission_file))
			return

		cmd = [ self._args.docker_executable, "create" ]
		if not self._args.no_network_isolation:
			cmd += [ "--network", "nonat", "--dns", "0.0.0.0", "--dns-search", "localdomain" ]
		cmd += [ self._args.docker_image, "/labwork/labwork-execute", self._args.server_uri, self._args.client_id, self._args.assignment ]
		container_id = subprocess.check_output(cmd).decode("ascii").rstrip("\r\n")

		subprocess.check_call([ self._args.docker_executable, "cp", submission_file, "%s:/labwork/labwork.tar.gz" % (container_id) ], stdout = subprocess.DEVNULL)
		subprocess.check_call([ self._args.docker_executable, "start", container_id ], stdout = subprocess.DEVNULL)

		instance = self._Instance(src_file = submission_file, container_id = container_id, start_time = time.time())
		self._running_instances.append(instance)
		if self._args.verbose >= 2:
			print("Instance %s started: %s" % (instance.container_id, instance.src_file))

	def _inspect_instance(self, container_id):
		output = subprocess.check_output([ self._args.docker_executable, "inspect", container_id ])
		return json.loads(output)[0]

	def _collect_instance(self, instance, exit):
		returncode = int(subprocess.check_output([ self._args.docker_executable, "wait", instance.container_id ]).decode())
		log = subprocess.check_output([ self._args.docker_executable, "logs", instance.container_id ], stderr = subprocess.STDOUT)
		finished_instance = self._FinishedInstance(instance = instance, exit = exit, returncode = returncode, log = log)
		self._collected_results.append(finished_instance)

	def _wait_for_completion_iteration(self):
		still_running = [ ]
		timed_out = [ ]
		finished = [ ]
		now = time.time()
		for instance in self._running_instances:
			info = self._inspect_instance(instance.container_id)
			status = info["State"]["Status"]
			if status == "running":
				runtime = now - instance.start_time
				if runtime < self._args.timeout_secs:
					still_running.append(instance)
					if self._args.verbose >= 2:
						print("Instance %s still running: %s" % (instance.container_id, instance.src_file))
				else:
					timed_out.append(instance)
					if self._args.verbose >= 1:
						print("Instance %s timed out: %s" % (instance.container_id, instance.src_file))
			else:
				finished.append(instance)
				if self._args.verbose >= 1:
					print("Instance %s finished: %s" % (instance.container_id, instance.src_file))
		return (still_running, timed_out, finished)

	def _wait_for_completion(self):
		while len(self._running_instances) > 0:
			(still_running, timed_out, finished) = self._wait_for_completion_iteration()
			self._running_instances = still_running
			self._timed_out_instances += timed_out
			self._finished_instances += finished
			if len(self._running_instances) > 0:
				time.sleep(3)

		print("%d instances finished, %d timed out. Collecting results." % (len(self._finished_instances), len(self._timed_out_instances)))

		# Then shut down timed out instances
		for instance in self._timed_out_instances:
			subprocess.check_call([ self._args.docker_executable, "stop", instance.container_id ])

		# Finally, collect results
		for instance in self._timed_out_instances:
			self._collect_instance(instance, "timeout")
		for instance in self._finished_instances:
			self._collect_instance(instance, "exit")

	def _present_results(self):
		for finished_instance in self._collected_results:
			print("%s (%s): %s returncode %d" % (finished_instance.instance.src_file, finished_instance.instance.container_id, finished_instance.exit, finished_instance.returncode))
			print(finished_instance.log.decode())
			print("-" * 120)

	def run_all(self):
		self.run(self._args.submission_file)
		self._wait_for_completion()
		self._present_results()

tcr = TestcaseRunner(args)
tcr.run_all()
